# core/container.py
import json
import logging
from google import genai
from google.genai import types
from config import settings
from utils.logger import setup_logger

logger = setup_logger("Container")

class Container:
    """
    å…¨èƒ½å•ä¾‹å®¹å™¨ï¼šç®¡ç† Clientã€æ¨¡å‹è½®æ¢ã€å…¨å±€é…ç½®
    """
    _client = None
    _profile_cache = None

    @classmethod
    def get_client(cls):
        """[Singleton] è·å– Gemini Clientï¼Œå…¨å±€å”¯ä¸€"""
        if cls._client is None:
            try:
                # åªéœ€è¦åˆå§‹åŒ–ä¸€æ¬¡ï¼Œä¸æ¶ˆè€—é¢åº¦
                cls._client = genai.Client(api_key=settings.GEMINI_KEY)
            except Exception as e:
                logger.critical(f"âŒ Client Init Failed: {e}")
                raise e
        return cls._client

    @classmethod
    def load_user_profile(cls, force_refresh=False):
        """[DRY Fix] ç»Ÿä¸€è¯»å–ç”¨æˆ·ç”»åƒ"""
        if cls._profile_cache and not force_refresh:
            return cls._profile_cache

        profile_path = settings.DATA_DIR / "user_profile.json"
        if profile_path.exists():
            try:
                with open(profile_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    cls._profile_cache = json.dumps(data, indent=2, ensure_ascii=False)
                    return cls._profile_cache
            except Exception as e:
                logger.error(f"Profile Read Error: {e}")
                return ""
        return ""

    @classmethod
    def call_brain(cls, contents, tools=None, config=None, tier_index=0):
        """
        ğŸ”¥ [Core Feature] è‡ªåŠ¨æŠ— RPD (Rate Limit) çš„è°ƒç”¨æ¥å£
        å¤§è„‘ (Agent) åªéœ€è¦è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œä¸éœ€è¦ç®¡åº•å±‚ç”¨çš„æ˜¯å“ªä¸ªæ¨¡å‹ã€‚
        """
        # 1. é€’å½’ç»ˆæ­¢æ¡ä»¶
        if tier_index >= len(settings.MODEL_TIERS):
            logger.critical("ğŸ’€ All Model Tiers Exhausted. System Offline.")
            return "âš ï¸ [SYSTEM CRITICAL] Google API Quota Depleted. All models unavailable."

        # 2. é€‰æ¨¡å‹ (ä» settings.MODEL_TIERS è¯»å–)
        current_model = settings.MODEL_TIERS[tier_index]
        client = cls.get_client()

        # 3. é»˜è®¤é…ç½®å…œåº•
        if config is None:
            config = types.GenerateContentConfig(temperature=0.3)
        
        # ğŸ”¥ [Safety Patch] å¼ºåˆ¶å…³é—­å®‰å…¨è¿‡æ»¤å™¨ï¼Œé˜²æ­¢è¯¯æ€å¯¼è‡´ (No output)
        # ç§äººç®¡å®¶ä¸éœ€è¦è¿‡åº¦æ•æ„Ÿçš„è¿‡æ»¤å™¨
        if not config.safety_settings:
            config.safety_settings = [
                types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE")
            ]
        
        # å¼ºåˆ¶æŠŠ tools å¡è¿› config (å¦‚æœæä¾›äº†)
        if tools:
            config.tools = tools

        try:
            # logger.info(f"ğŸ§  Linking to Cortex: {current_model} (Tier {tier_index})")
            
            response = client.models.generate_content(
                model=current_model,
                contents=contents,
                config=config
            )
            return response

        except Exception as e:
            error_str = str(e)
            # 4. æ•è· 429 (é…é¢è¶…é™) æˆ– 503 (æœåŠ¡å™¨è¿‡è½½)
            if "429" in error_str or "503" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                logger.warning(f"ğŸ“‰ Model {current_model} Failed ({error_str[:30]}...). Switching to Tier {tier_index + 1}...")
                return cls.call_brain(contents, tools, config, tier_index + 1)
            else:
                # å…¶ä»–é”™è¯¯ (å¦‚ Prompt å†…å®¹è¿è§„) ç›´æ¥æŠ›å‡º
                logger.error(f"âŒ Fatal Logic Error: {e}")
                raise e